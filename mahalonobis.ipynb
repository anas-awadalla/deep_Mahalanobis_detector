{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xDkBi1qF48om"
   },
   "source": [
    "# Run Mahalonobis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 79683,
     "status": "ok",
     "timestamp": 1582678263318,
     "user": {
      "displayName": "Chunjong Park",
      "photoUrl": "",
      "userId": "02892557745455474907"
     },
     "user_tz": 480
    },
    "id": "3qJkticW5JIn",
    "outputId": "00b44d95-957d-4d50-8de9-5b5c9f81083a"
   },
   "outputs": [],
   "source": [
    "#!tar -xf ./data/Imagenet_resize.tar.gz -C ./data/\n",
    "#!tar -xf ./data/LSUN_resize.tar.gz -C ./data/\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "YZ-gvXyO57ht",
    "outputId": "4c7e8444-3091-4d9f-8590-e3c64e403de1"
   },
   "outputs": [],
   "source": [
    "#!python OOD_Baseline_and_ODIN.py --dataset cifar10 --net_type resnet --gpu 0\n",
    "!python OOD_Generate_Mahalanobis.py --dataset cifar10 --net_type resnet --gpu 0\n",
    "!python OOD_Regression_Mahalanobis.py --net_type resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(net_type='resnet')\n",
      "evaluate the LID estimator\n",
      "load train data:  cifar10\n",
      "load train data:  FGSM  of  LID_10\n",
      "load train data:  FGSM  of  LID_20\n",
      "load train data:  FGSM  of  LID_30\n",
      "load train data:  FGSM  of  LID_40\n",
      "load train data:  FGSM  of  LID_50\n",
      "load train data:  FGSM  of  LID_60\n",
      "load train data:  FGSM  of  LID_70\n",
      "load train data:  FGSM  of  LID_80\n",
      "load train data:  FGSM  of  LID_90\n",
      "load train data:  BIM  of  LID_10\n",
      "load train data:  BIM  of  LID_20\n",
      "load train data:  BIM  of  LID_30\n",
      "load train data:  BIM  of  LID_40\n",
      "load train data:  BIM  of  LID_50\n",
      "load train data:  BIM  of  LID_60\n",
      "load train data:  BIM  of  LID_70\n",
      "load train data:  BIM  of  LID_80\n",
      "load train data:  BIM  of  LID_90\n",
      "load train data:  DeepFool  of  LID_10\n",
      "load train data:  DeepFool  of  LID_20\n",
      "load train data:  DeepFool  of  LID_30\n",
      "load train data:  DeepFool  of  LID_40\n",
      "load train data:  DeepFool  of  LID_50\n",
      "load train data:  DeepFool  of  LID_60\n",
      "load train data:  DeepFool  of  LID_70\n",
      "load train data:  DeepFool  of  LID_80\n",
      "load train data:  DeepFool  of  LID_90\n",
      "load train data:  CWL2  of  LID_10\n",
      "load train data:  CWL2  of  LID_20\n",
      "load train data:  CWL2  of  LID_30\n",
      "load train data:  CWL2  of  LID_40\n",
      "load train data:  CWL2  of  LID_50\n",
      "load train data:  CWL2  of  LID_60\n",
      "load train data:  CWL2  of  LID_70\n",
      "load train data:  CWL2  of  LID_80\n",
      "load train data:  CWL2  of  LID_90\n",
      "evaluate the Mahalanobis estimator\n",
      "load train data:  cifar10\n",
      "load train data:  FGSM  of  Mahalanobis_0.0\n",
      "load train data:  FGSM  of  Mahalanobis_0.01\n",
      "load train data:  FGSM  of  Mahalanobis_0.005\n",
      "load train data:  FGSM  of  Mahalanobis_0.002\n",
      "load train data:  FGSM  of  Mahalanobis_0.0014\n",
      "load train data:  FGSM  of  Mahalanobis_0.001\n",
      "load train data:  FGSM  of  Mahalanobis_0.0005\n",
      "load train data:  BIM  of  Mahalanobis_0.0\n",
      "load train data:  BIM  of  Mahalanobis_0.01\n",
      "load train data:  BIM  of  Mahalanobis_0.005\n",
      "load train data:  BIM  of  Mahalanobis_0.002\n",
      "load train data:  BIM  of  Mahalanobis_0.0014\n",
      "load train data:  BIM  of  Mahalanobis_0.001\n",
      "load train data:  BIM  of  Mahalanobis_0.0005\n",
      "load train data:  DeepFool  of  Mahalanobis_0.0\n",
      "load train data:  DeepFool  of  Mahalanobis_0.01\n",
      "load train data:  DeepFool  of  Mahalanobis_0.005\n",
      "load train data:  DeepFool  of  Mahalanobis_0.002\n",
      "load train data:  DeepFool  of  Mahalanobis_0.0014\n",
      "load train data:  DeepFool  of  Mahalanobis_0.001\n",
      "load train data:  DeepFool  of  Mahalanobis_0.0005\n",
      "load train data:  CWL2  of  Mahalanobis_0.0\n",
      "load train data:  CWL2  of  Mahalanobis_0.01\n",
      "load train data:  CWL2  of  Mahalanobis_0.005\n",
      "load train data:  CWL2  of  Mahalanobis_0.002\n",
      "load train data:  CWL2  of  Mahalanobis_0.0014\n",
      "load train data:  CWL2  of  Mahalanobis_0.001\n",
      "load train data:  CWL2  of  Mahalanobis_0.0005\n",
      "results of LID\n",
      "in_distribution: cifar10==========\n",
      "out_distribution: FGSM\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 98.73  99.64  97.36  99.82  99.22\n",
      "Input noise: LID_70\n",
      "\n",
      "out_distribution: BIM\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 73.64  94.13  87.26  96.60  90.43\n",
      "Input noise: LID_70\n",
      "\n",
      "out_distribution: DeepFool\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 55.49  88.72  80.90  93.61  80.24\n",
      "Input noise: LID_40\n",
      "\n",
      "out_distribution: CWL2\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 47.02  84.19  76.23  89.99  76.77\n",
      "Input noise: LID_70\n",
      "\n",
      "results of Mahalanobis\n",
      "in_distribution: cifar10==========\n",
      "out_distribution: FGSM\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 99.97  99.96  99.88  99.91  99.94\n",
      "Input noise: Mahalanobis_0.0005\n",
      "\n",
      "out_distribution: BIM\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 98.84  99.52  97.47  99.55  99.14\n",
      "Input noise: Mahalanobis_0.0005\n",
      "\n",
      "out_distribution: DeepFool\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 61.98  91.45  84.13  95.02  85.02\n",
      "Input noise: Mahalanobis_0.0005\n",
      "\n",
      "out_distribution: CWL2\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 79.87  95.78  89.70  97.44  92.01\n",
      "Input noise: Mahalanobis_0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model: ResNet, in-distribution: CIFAR-10, adversarial attack: FGSM  gpu: 0\n",
    "#!python ADV_Samples.py --dataset cifar10 --net_type resnet --adv_type FGSM --gpu 0\n",
    "#!python ADV_Samples.py --dataset cifar10 --net_type resnet --adv_type BIM --gpu 0\n",
    "#!python ADV_Samples.py --dataset cifar10 --net_type resnet --adv_type DeepFool --gpu 0\n",
    "#!python ADV_Samples.py --dataset cifar10 --net_type resnet --adv_type CWL2 --gpu 0\n",
    "#!python ADV_Generate_LID_Mahalanobis.py --dataset cifar10 --net_type resnet --adv_type FGSM --gpu 0\n",
    "#!python ADV_Generate_LID_Mahalanobis.py --dataset cifar10 --net_type resnet --adv_type BIM --gpu 0\n",
    "#!python ADV_Generate_LID_Mahalanobis.py --dataset cifar10 --net_type resnet --adv_type DeepFool --gpu 0\n",
    "#!python ADV_Generate_LID_Mahalanobis.py --dataset cifar10 --net_type resnet --adv_type CWL2 --gpu 0\n",
    "!python ADV_Regression.py --net_type resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=16, dataroot='./data', dataset='ham10000', gpu=0, net_type='densenet121', num_classes=7, outf='./output/')\n",
      "load model: densenet121\n",
      "load target data:  ham10000\n",
      "get sample mean and covariance\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:69: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data = Variable(data, volatile=True)\n",
      "\n",
      " Training Accuracy:(94.62%)\n",
      "\n",
      "get Mahalanobis scores 5\n",
      "Noise: 0.0\n",
      "layer_num 0\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:197: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  noise_out_features = model.intermediate_forward(Variable(tempInputs, volatile=True), layer_index)\n",
      "layer_num 1\n",
      "layer_num 2\n",
      "layer_num 3\n",
      "layer_num 4\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Out-distribution: cifar10\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Out-distribution: cifar100\n",
      "Using downloaded and verified file: ./data/svhn-data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/svhn-data/test_32x32.mat\n",
      "Out-distribution: svhn\n",
      "Out-distribution: imagenet_resize\n",
      "Out-distribution: lsun_resize\n",
      "Out-distribution: face\n",
      "Out-distribution: face_age\n",
      "Out-distribution: isic-2017\n",
      "Out-distribution: isic-2016\n",
      "Noise: 0.01\n",
      "layer_num 0\n",
      "layer_num 1\n",
      "layer_num 2\n",
      "layer_num 3\n",
      "layer_num 4\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Out-distribution: cifar10\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Out-distribution: cifar100\n",
      "Using downloaded and verified file: ./data/svhn-data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/svhn-data/test_32x32.mat\n",
      "Out-distribution: svhn\n",
      "Out-distribution: imagenet_resize\n",
      "Out-distribution: lsun_resize\n",
      "Out-distribution: face\n",
      "Out-distribution: face_age\n",
      "Out-distribution: isic-2017\n",
      "Out-distribution: isic-2016\n",
      "Noise: 0.005\n",
      "layer_num 0\n",
      "layer_num 1\n",
      "layer_num 2\n",
      "layer_num 3\n",
      "layer_num 4\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Out-distribution: cifar10\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Out-distribution: cifar100\n",
      "Using downloaded and verified file: ./data/svhn-data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/svhn-data/test_32x32.mat\n",
      "Out-distribution: svhn\n",
      "Out-distribution: imagenet_resize\n",
      "Out-distribution: lsun_resize\n",
      "Out-distribution: face\n",
      "Out-distribution: face_age\n",
      "Out-distribution: isic-2017\n",
      "Out-distribution: isic-2016\n",
      "Noise: 0.002\n",
      "layer_num 0\n",
      "layer_num 1\n",
      "layer_num 2\n",
      "layer_num 3\n",
      "layer_num 4\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Out-distribution: cifar10\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Out-distribution: cifar100\n",
      "Using downloaded and verified file: ./data/svhn-data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/svhn-data/test_32x32.mat\n",
      "Out-distribution: svhn\n",
      "Out-distribution: imagenet_resize\n",
      "Out-distribution: lsun_resize\n",
      "Out-distribution: face\n",
      "Out-distribution: face_age\n",
      "Out-distribution: isic-2017\n",
      "Out-distribution: isic-2016\n",
      "Noise: 0.0014\n",
      "layer_num 0\n",
      "layer_num 1\n",
      "layer_num 2\n",
      "layer_num 3\n",
      "layer_num 4\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Out-distribution: cifar10\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Out-distribution: cifar100\n",
      "Using downloaded and verified file: ./data/svhn-data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/svhn-data/test_32x32.mat\n",
      "Out-distribution: svhn\n",
      "Out-distribution: imagenet_resize\n",
      "Out-distribution: lsun_resize\n",
      "Out-distribution: face\n",
      "Out-distribution: face_age\n",
      "Out-distribution: isic-2017\n",
      "Out-distribution: isic-2016\n",
      "Noise: 0.001\n",
      "layer_num 0\n",
      "layer_num 1\n",
      "layer_num 2\n",
      "layer_num 3\n",
      "layer_num 4\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Out-distribution: cifar10\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Out-distribution: cifar100\n",
      "Using downloaded and verified file: ./data/svhn-data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/svhn-data/test_32x32.mat\n",
      "Out-distribution: svhn\n",
      "Out-distribution: imagenet_resize\n",
      "Out-distribution: lsun_resize\n",
      "Out-distribution: face\n",
      "Out-distribution: face_age\n",
      "Out-distribution: isic-2017\n",
      "Out-distribution: isic-2016\n",
      "Noise: 0.0005\n",
      "layer_num 0\n",
      "layer_num 1\n",
      "layer_num 2\n",
      "layer_num 3\n",
      "layer_num 4\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Out-distribution: cifar10\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Out-distribution: cifar100\n",
      "Using downloaded and verified file: ./data/svhn-data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/svhn-data/test_32x32.mat\n",
      "Out-distribution: svhn\n",
      "Out-distribution: imagenet_resize\n",
      "Out-distribution: lsun_resize\n",
      "Out-distribution: face\n",
      "Out-distribution: face_age\n",
      "Out-distribution: isic-2017\n",
      "Out-distribution: isic-2016\n"
     ]
    }
   ],
   "source": [
    "!python OOD_Generate_Mahalanobis.py --dataset ham10000 --net_type densenet121 --num_classes 7 --batch_size 16 --gpu 0\n",
    "#!python OOD_Regression_Mahalanobis.py --net_type resnet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(net_type='densenet121')\n",
      "In-distribution:  ham10000\n",
      "Out-of-distribution:  cifar10\n",
      "Out-of-distribution:  cifar100\n",
      "Out-of-distribution:  svhn\n",
      "Out-of-distribution:  imagenet_resize\n",
      "Out-of-distribution:  lsun_resize\n",
      "Out-of-distribution:  face\n",
      "Out-of-distribution:  face_age\n",
      "Out-of-distribution:  isic-2017\n",
      "Out-of-distribution:  isic-2016\n",
      "in_distribution: ham10000==========\n",
      "out_distribution: cifar10\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "100.00 100.00  99.91  99.90  99.99\n",
      "Input noise: Mahalanobis_0.0\n",
      "\n",
      "out_distribution: cifar100\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 99.96  99.96  99.86  97.94  99.99\n",
      "Input noise: Mahalanobis_0.005\n",
      "\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "100.00 100.00  99.84  99.84 100.00\n",
      "Input noise: Mahalanobis_0.005\n",
      "\n",
      "out_distribution: imagenet_resize\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "100.00  99.82  99.89  99.75  99.83\n",
      "Input noise: Mahalanobis_0.0\n",
      "\n",
      "out_distribution: lsun_resize\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "100.00 100.00  99.99  99.91  99.99\n",
      "Input noise: Mahalanobis_0.0\n",
      "\n",
      "out_distribution: face\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "100.00  99.99  99.91  99.91  99.48\n",
      "Input noise: Mahalanobis_0.01\n",
      "\n",
      "out_distribution: face_age\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "100.00  99.92  99.79  99.73  99.99\n",
      "Input noise: Mahalanobis_0.0\n",
      "\n",
      "out_distribution: isic-2017\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 47.33  89.16  83.58  92.69  79.70\n",
      "Input noise: Mahalanobis_0.001\n",
      "\n",
      "out_distribution: isic-2016\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 17.88  68.12  65.69  74.32  57.70\n",
      "Input noise: Mahalanobis_0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python OOD_Regression_Mahalanobis.py --net_type densenet121 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(adv_type='FGSM', batch_size=16, dataroot='./data', dataset='ham10000', gpu=0, net_type='densenet121', num_classes=7, outf='./adv_output/')\n",
      "load model: densenet121\n",
      "load target data:  ham10000\n",
      "Attack: FGSM, Dist: ham10000\n",
      "\n",
      "ADV_Samples.py:179: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "ADV_Samples.py:272: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  output = model(Variable(adv_data, volatile=True))\n",
      "ADV_Samples.py:278: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  output = model(Variable(noisy_data, volatile=True))\n",
      "Adversarial Noise:(0.25)\n",
      "\n",
      "Final Accuracy: 1009/1103 (91.48%)\n",
      "\n",
      "Adversarial Accuracy: 279/1103 (25.29%)\n",
      "\n",
      "Noisy Accuracy: 1005/1103 (91.12%)\n",
      "\n",
      "Namespace(adv_type='BIM', batch_size=16, dataroot='./data', dataset='ham10000', gpu=0, net_type='densenet121', num_classes=7, outf='./adv_output/')\n",
      "load model: densenet121\n",
      "load target data:  ham10000\n",
      "Attack: BIM, Dist: ham10000\n",
      "\n",
      "ADV_Samples.py:179: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "ADV_Samples.py:272: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  output = model(Variable(adv_data, volatile=True))\n",
      "ADV_Samples.py:278: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  output = model(Variable(noisy_data, volatile=True))\n",
      "Adversarial Noise:(0.26)\n",
      "\n",
      "Final Accuracy: 1009/1103 (91.48%)\n",
      "\n",
      "Adversarial Accuracy: 0/1103 (0.00%)\n",
      "\n",
      "Noisy Accuracy: 1006/1103 (91.21%)\n",
      "\n",
      "Namespace(adv_type='DeepFool', batch_size=16, dataroot='./data', dataset='ham10000', gpu=0, net_type='densenet121', num_classes=7, outf='./adv_output/')\n",
      "load model: densenet121\n",
      "load target data:  ham10000\n",
      "Attack: DeepFool, Dist: ham10000\n",
      "\n",
      "ADV_Samples.py:179: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib/util.py:116: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  imgsvar = torch.autograd.Variable(imgs.squeeze(), volatile=True)\n",
      "ADV_Samples.py:272: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  output = model(Variable(adv_data, volatile=True))\n",
      "ADV_Samples.py:278: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  output = model(Variable(noisy_data, volatile=True))\n",
      "Adversarial Noise:(0.17)\n",
      "\n",
      "Final Accuracy: 1009/1103 (91.48%)\n",
      "\n",
      "Adversarial Accuracy: 0/1103 (0.00%)\n",
      "\n",
      "Noisy Accuracy: 991/1103 (89.85%)\n",
      "\n",
      "Namespace(adv_type='CWL2', batch_size=16, dataroot='./data', dataset='ham10000', gpu=0, net_type='densenet121', num_classes=7, outf='./adv_output/')\n",
      "load model: densenet121\n",
      "load target data:  ham10000\n",
      "Attack: CWL2, Dist: ham10000\n",
      "\n",
      "ADV_Samples.py:179: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib/util.py:116: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  imgsvar = torch.autograd.Variable(imgs.squeeze(), volatile=True)\n",
      "ADV_Samples.py:272: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  output = model(Variable(adv_data, volatile=True))\n",
      "ADV_Samples.py:278: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  output = model(Variable(noisy_data, volatile=True))\n",
      "Adversarial Noise:(0.02)\n",
      "\n",
      "Final Accuracy: 1009/1103 (91.48%)\n",
      "\n",
      "Adversarial Accuracy: 0/1103 (0.00%)\n",
      "\n",
      "Noisy Accuracy: 1011/1103 (91.66%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ADV_Samples.py --dataset ham10000 --net_type densenet121 --adv_type FGSM --gpu 0 --num_classes 7 --batch_size 16\n",
    "!python ADV_Samples.py --dataset ham10000 --net_type densenet121 --adv_type BIM --gpu 0 --num_classes 7 --batch_size 16\n",
    "!python ADV_Samples.py --dataset ham10000 --net_type densenet121 --adv_type DeepFool --gpu 0 --num_classes 7 --batch_size 16\n",
    "!python ADV_Samples.py --dataset ham10000 --net_type densenet121 --adv_type CWL2 --gpu 0 --num_classes 7 --batch_size 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 23 17:06:35 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.40.04    Driver Version: 418.40.04    CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  On   | 00000000:3D:00.0 Off |                  N/A |\r\n",
      "| 32%   28C    P8     7W / 250W |      0MiB / 10989MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(adv_type='FGSM', batch_size=16, dataroot='./data', dataset='ham10000', gpu=0, net_type='densenet121', num_classes=7, outf='./adv_output/')\n",
      "load model: densenet121\n",
      "load target data:  ham10000\n",
      "get sample mean and covariance\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:70: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data = Variable(data, volatile=True)\n",
      "\n",
      " Training Accuracy:(94.62%)\n",
      "\n",
      "get LID scores\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:380: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:393: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  output, out_features = model.feature_list(Variable(adv_data, volatile=True))\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:404: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  output, out_features = model.feature_list(Variable(noisy_data, volatile=True))\n",
      "get Mahalanobis scores\n",
      "\n",
      "Noise: 0.0\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:336: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  noise_out_features = model.intermediate_forward(Variable(tempInputs, volatile=True), layer_index)\n",
      "\n",
      "Noise: 0.01\n",
      "\n",
      "Noise: 0.005\n",
      "\n",
      "Noise: 0.002\n",
      "\n",
      "Noise: 0.0014\n",
      "\n",
      "Noise: 0.001\n",
      "\n",
      "Noise: 0.0005\n",
      "Namespace(adv_type='BIM', batch_size=16, dataroot='./data', dataset='ham10000', gpu=0, net_type='densenet121', num_classes=7, outf='./adv_output/')\n",
      "load model: densenet121\n",
      "load target data:  ham10000\n",
      "get sample mean and covariance\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:70: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data = Variable(data, volatile=True)\n",
      "\n",
      " Training Accuracy:(94.62%)\n",
      "\n",
      "get LID scores\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:380: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:393: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  output, out_features = model.feature_list(Variable(adv_data, volatile=True))\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:404: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  output, out_features = model.feature_list(Variable(noisy_data, volatile=True))\n",
      "get Mahalanobis scores\n",
      "\n",
      "Noise: 0.0\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:336: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  noise_out_features = model.intermediate_forward(Variable(tempInputs, volatile=True), layer_index)\n",
      "\n",
      "Noise: 0.01\n",
      "\n",
      "Noise: 0.005\n",
      "\n",
      "Noise: 0.002\n",
      "\n",
      "Noise: 0.0014\n",
      "\n",
      "Noise: 0.001\n",
      "\n",
      "Noise: 0.0005\n",
      "Namespace(adv_type='DeepFool', batch_size=16, dataroot='./data', dataset='ham10000', gpu=0, net_type='densenet121', num_classes=7, outf='./adv_output/')\n",
      "load model: densenet121\n",
      "load target data:  ham10000\n",
      "get sample mean and covariance\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:70: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data = Variable(data, volatile=True)\n",
      "\n",
      " Training Accuracy:(94.62%)\n",
      "\n",
      "get LID scores\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:380: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:393: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  output, out_features = model.feature_list(Variable(adv_data, volatile=True))\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:404: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  output, out_features = model.feature_list(Variable(noisy_data, volatile=True))\n",
      "get Mahalanobis scores\n",
      "\n",
      "Noise: 0.0\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:336: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  noise_out_features = model.intermediate_forward(Variable(tempInputs, volatile=True), layer_index)\n",
      "\n",
      "Noise: 0.01\n",
      "\n",
      "Noise: 0.005\n",
      "\n",
      "Noise: 0.002\n",
      "\n",
      "Noise: 0.0014\n",
      "\n",
      "Noise: 0.001\n",
      "\n",
      "Noise: 0.0005\n",
      "Namespace(adv_type='CWL2', batch_size=16, dataroot='./data', dataset='ham10000', gpu=0, net_type='densenet121', num_classes=7, outf='./adv_output/')\n",
      "load model: densenet121\n",
      "load target data:  ham10000\n",
      "get sample mean and covariance\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:70: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data = Variable(data, volatile=True)\n",
      "\n",
      " Training Accuracy:(94.62%)\n",
      "\n",
      "get LID scores\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:380: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:393: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  output, out_features = model.feature_list(Variable(adv_data, volatile=True))\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:404: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  output, out_features = model.feature_list(Variable(noisy_data, volatile=True))\n",
      "get Mahalanobis scores\n",
      "\n",
      "Noise: 0.0\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:336: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  noise_out_features = model.intermediate_forward(Variable(tempInputs, volatile=True), layer_index)\n",
      "\n",
      "Noise: 0.01\n",
      "\n",
      "Noise: 0.005\n",
      "\n",
      "Noise: 0.002\n",
      "\n",
      "Noise: 0.0014\n",
      "\n",
      "Noise: 0.001\n",
      "\n",
      "Noise: 0.0005\n"
     ]
    }
   ],
   "source": [
    "!python ADV_Generate_LID_Mahalanobis.py --dataset ham10000 --net_type densenet121 --adv_type FGSM --gpu 0 --num_classes 7 --batch_size 16 \n",
    "!python ADV_Generate_LID_Mahalanobis.py --dataset ham10000 --net_type densenet121 --adv_type BIM --gpu 0 --num_classes 7 --batch_size 16 \n",
    "!python ADV_Generate_LID_Mahalanobis.py --dataset ham10000 --net_type densenet121 --adv_type DeepFool --gpu 0 --num_classes 7 --batch_size 16 \n",
    "!python ADV_Generate_LID_Mahalanobis.py --dataset ham10000 --net_type densenet121 --adv_type CWL2 --gpu 0 --num_classes 7 --batch_size 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(net_type='densenet121')\n",
      "evaluate the LID estimator\n",
      "load train data:  ham10000\n",
      "load train data:  FGSM  of  LID_10\n",
      "load train data:  FGSM  of  LID_20\n",
      "load train data:  FGSM  of  LID_30\n",
      "load train data:  FGSM  of  LID_40\n",
      "load train data:  FGSM  of  LID_50\n",
      "load train data:  FGSM  of  LID_60\n",
      "load train data:  FGSM  of  LID_70\n",
      "load train data:  FGSM  of  LID_80\n",
      "load train data:  FGSM  of  LID_90\n",
      "load train data:  BIM  of  LID_10\n",
      "load train data:  BIM  of  LID_20\n",
      "load train data:  BIM  of  LID_30\n",
      "load train data:  BIM  of  LID_40\n",
      "load train data:  BIM  of  LID_50\n",
      "load train data:  BIM  of  LID_60\n",
      "load train data:  BIM  of  LID_70\n",
      "load train data:  BIM  of  LID_80\n",
      "load train data:  BIM  of  LID_90\n",
      "load train data:  DeepFool  of  LID_10\n",
      "load train data:  DeepFool  of  LID_20\n",
      "load train data:  DeepFool  of  LID_30\n",
      "load train data:  DeepFool  of  LID_40\n",
      "load train data:  DeepFool  of  LID_50\n",
      "load train data:  DeepFool  of  LID_60\n",
      "load train data:  DeepFool  of  LID_70\n",
      "load train data:  DeepFool  of  LID_80\n",
      "load train data:  DeepFool  of  LID_90\n",
      "load train data:  CWL2  of  LID_10\n",
      "load train data:  CWL2  of  LID_20\n",
      "load train data:  CWL2  of  LID_30\n",
      "load train data:  CWL2  of  LID_40\n",
      "load train data:  CWL2  of  LID_50\n",
      "load train data:  CWL2  of  LID_60\n",
      "load train data:  CWL2  of  LID_70\n",
      "load train data:  CWL2  of  LID_80\n",
      "load train data:  CWL2  of  LID_90\n",
      "evaluate the Mahalanobis estimator\n",
      "load train data:  ham10000\n",
      "load train data:  FGSM  of  Mahalanobis_0.0\n",
      "load train data:  FGSM  of  Mahalanobis_0.01\n",
      "load train data:  FGSM  of  Mahalanobis_0.005\n",
      "load train data:  FGSM  of  Mahalanobis_0.002\n",
      "load train data:  FGSM  of  Mahalanobis_0.0014\n",
      "load train data:  FGSM  of  Mahalanobis_0.001\n",
      "load train data:  FGSM  of  Mahalanobis_0.0005\n",
      "load train data:  BIM  of  Mahalanobis_0.0\n",
      "load train data:  BIM  of  Mahalanobis_0.01\n",
      "load train data:  BIM  of  Mahalanobis_0.005\n",
      "load train data:  BIM  of  Mahalanobis_0.002\n",
      "load train data:  BIM  of  Mahalanobis_0.0014\n",
      "load train data:  BIM  of  Mahalanobis_0.001\n",
      "load train data:  BIM  of  Mahalanobis_0.0005\n",
      "load train data:  DeepFool  of  Mahalanobis_0.0\n",
      "load train data:  DeepFool  of  Mahalanobis_0.01\n",
      "load train data:  DeepFool  of  Mahalanobis_0.005\n",
      "load train data:  DeepFool  of  Mahalanobis_0.002\n",
      "load train data:  DeepFool  of  Mahalanobis_0.0014\n",
      "load train data:  DeepFool  of  Mahalanobis_0.001\n",
      "load train data:  DeepFool  of  Mahalanobis_0.0005\n",
      "load train data:  CWL2  of  Mahalanobis_0.0\n",
      "load train data:  CWL2  of  Mahalanobis_0.01\n",
      "load train data:  CWL2  of  Mahalanobis_0.005\n",
      "load train data:  CWL2  of  Mahalanobis_0.002\n",
      "load train data:  CWL2  of  Mahalanobis_0.0014\n",
      "load train data:  CWL2  of  Mahalanobis_0.001\n",
      "load train data:  CWL2  of  Mahalanobis_0.0005\n",
      "results of LID\n",
      "in_distribution: ham10000==========\n",
      "out_distribution: FGSM\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 97.44  99.07  96.52  99.38  97.77\n",
      "Input noise: LID_60\n",
      "\n",
      "out_distribution: BIM\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "100.00  99.99  99.65  99.94  99.88\n",
      "Input noise: LID_20\n",
      "\n",
      "out_distribution: DeepFool\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 25.00  77.17  72.03  84.78  61.33\n",
      "Input noise: LID_90\n",
      "\n",
      "out_distribution: CWL2\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 35.28  83.97  78.53  89.89  69.29\n",
      "Input noise: LID_80\n",
      "\n",
      "results of Mahalanobis\n",
      "in_distribution: ham10000==========\n",
      "out_distribution: FGSM\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "100.00 100.00  99.93  99.93  99.86\n",
      "Input noise: Mahalanobis_0.0\n",
      "\n",
      "out_distribution: BIM\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "100.00  99.99  99.90  99.95  99.89\n",
      "Input noise: Mahalanobis_0.01\n",
      "\n",
      "out_distribution: DeepFool\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 40.00  85.40  77.76  90.86  72.39\n",
      "Input noise: Mahalanobis_0.005\n",
      "\n",
      "out_distribution: CWL2\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 36.90  81.66  75.86  86.65  68.79\n",
      "Input noise: Mahalanobis_0.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ADV_Regression.py --net_type densenet121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr  7 11:22:43 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.40.04    Driver Version: 418.40.04    CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  On   | 00000000:3D:00.0 Off |                  N/A |\r\n",
      "| 32%   30C    P0    50W / 250W |      0MiB / 10989MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=16, dataroot='./data', dataset='ham10000', gpu=0, net_type='densenet121', num_classes=7, outf='./output/')\n",
      "load model: densenet121\n",
      "load target data:  ham10000\n",
      "get sample mean and covariance\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:70: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data = Variable(data, volatile=True)\n",
      "\n",
      " Training Accuracy:(94.62%)\n",
      "\n",
      "get Mahalanobis scores 5\n",
      "Noise: 0.0\n",
      "layer_num 0\n",
      "/gscratch/cse/cjparkuw/git/deep_Mahalanobis_detector/lib_generation.py:198: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  noise_out_features = model.intermediate_forward(Variable(tempInputs, volatile=True), layer_index)\n",
      "layer_num 1\n",
      "layer_num 2\n",
      "layer_num 3\n",
      "layer_num 4\n",
      "Out-distribution: ham10000-avg-smoothing\n",
      "Out-distribution: ham10000-brightness\n",
      "Out-distribution: ham10000-contrast\n",
      "Out-distribution: ham10000-dilation\n",
      "Out-distribution: ham10000-erosion\n",
      "Out-distribution: ham10000-med-smoothing\n",
      "Out-distribution: ham10000-rotation\n",
      "Out-distribution: ham10000-shift\n",
      "Noise: 0.01\n",
      "layer_num 0\n",
      "layer_num 1\n",
      "layer_num 2\n",
      "layer_num 3\n",
      "layer_num 4\n",
      "Out-distribution: ham10000-avg-smoothing\n",
      "Out-distribution: ham10000-brightness\n",
      "Out-distribution: ham10000-contrast\n",
      "Out-distribution: ham10000-dilation\n",
      "Out-distribution: ham10000-erosion\n",
      "Out-distribution: ham10000-med-smoothing\n",
      "Out-distribution: ham10000-rotation\n",
      "Out-distribution: ham10000-shift\n",
      "Noise: 0.005\n",
      "layer_num 0\n",
      "layer_num 1\n",
      "layer_num 2\n",
      "layer_num 3\n",
      "layer_num 4\n",
      "Out-distribution: ham10000-avg-smoothing\n",
      "Out-distribution: ham10000-brightness\n",
      "Out-distribution: ham10000-contrast\n",
      "Out-distribution: ham10000-dilation\n",
      "Out-distribution: ham10000-erosion\n",
      "Out-distribution: ham10000-med-smoothing\n",
      "Out-distribution: ham10000-rotation\n",
      "Out-distribution: ham10000-shift\n",
      "Noise: 0.002\n",
      "layer_num 0\n",
      "layer_num 1\n",
      "layer_num 2\n",
      "layer_num 3\n",
      "layer_num 4\n",
      "Out-distribution: ham10000-avg-smoothing\n",
      "Out-distribution: ham10000-brightness\n",
      "Out-distribution: ham10000-contrast\n",
      "Out-distribution: ham10000-dilation\n",
      "Out-distribution: ham10000-erosion\n",
      "Out-distribution: ham10000-med-smoothing\n",
      "Out-distribution: ham10000-rotation\n",
      "Out-distribution: ham10000-shift\n",
      "Noise: 0.0014\n",
      "layer_num 0\n",
      "layer_num 1\n",
      "layer_num 2\n",
      "layer_num 3\n",
      "layer_num 4\n",
      "Out-distribution: ham10000-avg-smoothing\n",
      "Out-distribution: ham10000-brightness\n",
      "Out-distribution: ham10000-contrast\n",
      "Out-distribution: ham10000-dilation\n",
      "Out-distribution: ham10000-erosion\n",
      "Out-distribution: ham10000-med-smoothing\n",
      "Out-distribution: ham10000-rotation\n",
      "Out-distribution: ham10000-shift\n",
      "Noise: 0.001\n",
      "layer_num 0\n",
      "layer_num 1\n",
      "layer_num 2\n",
      "layer_num 3\n",
      "layer_num 4\n",
      "Out-distribution: ham10000-avg-smoothing\n",
      "Out-distribution: ham10000-brightness\n",
      "Out-distribution: ham10000-contrast\n",
      "Out-distribution: ham10000-dilation\n",
      "Out-distribution: ham10000-erosion\n",
      "Out-distribution: ham10000-med-smoothing\n",
      "Out-distribution: ham10000-rotation\n",
      "Out-distribution: ham10000-shift\n",
      "Noise: 0.0005\n",
      "layer_num 0\n",
      "layer_num 1\n",
      "layer_num 2\n",
      "layer_num 3\n",
      "layer_num 4\n",
      "Out-distribution: ham10000-avg-smoothing\n",
      "Out-distribution: ham10000-brightness\n",
      "Out-distribution: ham10000-contrast\n",
      "Out-distribution: ham10000-dilation\n",
      "Out-distribution: ham10000-erosion\n",
      "Out-distribution: ham10000-med-smoothing\n",
      "Out-distribution: ham10000-rotation\n",
      "Out-distribution: ham10000-shift\n"
     ]
    }
   ],
   "source": [
    "!python OOD_Generate_Mahalanobis.py --dataset ham10000 --net_type densenet121 --num_classes 7 --batch_size 16 --gpu 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(net_type='densenet121')\n",
      "In-distribution:  ham10000\n",
      "Out-of-distribution:  ham10000-avg-smoothing\n",
      "Out-of-distribution:  ham10000-brightness\n",
      "Out-of-distribution:  ham10000-contrast\n",
      "Out-of-distribution:  ham10000-dilation\n",
      "Out-of-distribution:  ham10000-erosion\n",
      "Out-of-distribution:  ham10000-med-smoothing\n",
      "Out-of-distribution:  ham10000-rotation\n",
      "Out-of-distribution:  ham10000-shift\n",
      "in_distribution: ham10000==========\n",
      "out_distribution: ham10000-avg-smoothing\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 71.40  93.62  88.94  66.18  98.90\n",
      "Input noise: Mahalanobis_0.0\n",
      "\n",
      "out_distribution: ham10000-brightness\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 81.65  96.07  89.15  77.23  99.52\n",
      "Input noise: Mahalanobis_0.0\n",
      "\n",
      "out_distribution: ham10000-contrast\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 99.92  99.98  99.84  99.74  99.99\n",
      "Input noise: Mahalanobis_0.005\n",
      "\n",
      "out_distribution: ham10000-dilation\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 41.14  88.23  80.89  65.36  97.66\n",
      "Input noise: Mahalanobis_0.01\n",
      "\n",
      "out_distribution: ham10000-erosion\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 74.68  94.72  88.90  66.06  99.31\n",
      "Input noise: Mahalanobis_0.0005\n",
      "\n",
      "out_distribution: ham10000-med-smoothing\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 31.89  87.91  81.05  61.43  97.64\n",
      "Input noise: Mahalanobis_0.01\n",
      "\n",
      "out_distribution: ham10000-rotation\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 96.73  98.43  95.91  88.77  99.71\n",
      "Input noise: Mahalanobis_0.0\n",
      "\n",
      "out_distribution: ham10000-shift\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "100.00 100.00  99.98  99.91  99.99\n",
      "Input noise: Mahalanobis_0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python OOD_Regression_Mahalanobis.py --net_type densenet121 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNsMQxZ4n+3hic34gtYsPyT",
   "name": "mahalonobis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
